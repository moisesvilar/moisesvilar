<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Write some code!</title>
    <link>https://moisesvilar.github.io/post/index.xml</link>
    <description>Recent content in Posts on Write some code!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es-ES</language>
    <copyright>&amp;copy; Esta obra está bajo una &lt;a target=&#39;_blank&#39; rel=&#39;license&#39; href=&#39;http://creativecommons.org/licenses/by/4.0/&#39;&gt;Licencia Creative Commons Atribución 4.0 Internacional&lt;/a&gt;.</copyright>
    <lastBuildDate>Tue, 10 Jan 2017 19:51:45 +0100</lastBuildDate>
    <atom:link href="https://moisesvilar.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>docker II - capas e imágenes</title>
      <link>https://moisesvilar.github.io/post/docker-layers-2/</link>
      <pubDate>Tue, 10 Jan 2017 19:51:45 +0100</pubDate>
      
      <guid>https://moisesvilar.github.io/post/docker-layers-2/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://moisesvilar.github.io/post/docker-basics-1/&#34;&gt;En el anterior post&lt;/a&gt; vimos que una de las herramientas heredadas de Unix que utilizaba Docker eran los chroot.
Con ellos, podíamos establecer para un proceso &lt;strong&gt;en qué directorio comenzaba su sistema de ficheros&lt;/strong&gt;, su &lt;em&gt;carpeta raíz&lt;/em&gt;. También dijimos que, en la gestión de dicho sistema de ficheros,
Docker era bastante eficiente.&lt;/p&gt;

&lt;p&gt;En este post veremos en qué consiste esta eficiencia y cómo la consigue Docker.&lt;/p&gt;

&lt;h1 id=&#34;las-capas&#34;&gt;Las capas&lt;/h1&gt;

&lt;p&gt;Imaginémonos que tenemos dos entornos de ejecución para dos aplicaciones.
Ambos se ejecutan sobre el sistema operativo CentOS 7. Pero la primera,
es una aplicación basada en la API 6 de Java. Porque somos tipos duros. Y la segunda es
una aplicación NodeJS 6.9.&lt;/p&gt;

&lt;p&gt;Vamos a hacer el ejercicio mental de montar sendos entornos de ejecución en dos máquinas virtuales.&lt;/p&gt;

&lt;p&gt;Para la &lt;strong&gt;primera máquina virtual&lt;/strong&gt;, la que reproduce el entorno de ejecución de la aplicación Java,
tendremos que instalar:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;El sistema operativo CentOS 7.&lt;/li&gt;
&lt;li&gt;La máquina virtual de Java para la versión 6 de su API.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Para la &lt;strong&gt;segunda máquina virtual&lt;/strong&gt;, la de la aplicación NodeJS:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;El sistema operativo CentOS 7 &lt;em&gt;again&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;El servidor NodeJS en su versión 6.9.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Fijaos en el primer punto de ambas máquinas, el sistema operativo CentOS 7.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;¿Todos los ficheros binarios que componen dicho sistema operativo están duplicados en ambas máquinas?&lt;/strong&gt;
Por supuesto que sí.&lt;/p&gt;

&lt;p&gt;Tendríamos algo como esto:&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-vm-1.png&#34; alt=&#34;Entorno en cada máquina virtual&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Esto no parece que sea muy eficiente. Es decir, ambas máquinas duplican &lt;strong&gt;exactamente&lt;/strong&gt; los mismos
binarios para el sistema operativo.&lt;/p&gt;

&lt;p&gt;¿Qué pasaría si dichos binarios se pudiesen &lt;strong&gt;reutilizar&lt;/strong&gt; entre ambas máquinas? En este escenario,
ganaríamos eficiencia, ya que ambas máquinas compartirían los ficheros del sistema operativo
(al fin y al cabo, es el mismo para ambos entornos). La única condición que necesitaríamos es que
dichos binarios fueran de &lt;strong&gt;sólo lectura&lt;/strong&gt;, para evitar que una escritura de la primera máquina
cambiase el entorno de la segunda y ésta se fuese al garete.&lt;/p&gt;

&lt;p&gt;En este segundo caso tendríamos:&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-vm-2.png&#34; alt=&#34;Entorno compartido en dos máquinas virtuales&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Bien, ahora bauticemos las cosas. Resulta que a un conjunto de binarios (por ejemplo, los que
componen el sistema operativo CentOS 7) se le denomina &lt;strong&gt;una capa&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Este concepto de &lt;strong&gt;capas reutilizables&lt;/strong&gt; es lo que emplea Docker para ganar eficiencia entre
las &amp;ldquo;máquinas virtuales&amp;rdquo; (con todas las comillas que queráis) que gestiona. Es decir, la arquitectura
de capas que emplearía Docker para modelizar los entornos del ejemplo sería la de la segunda figura,
reutilizando la capa del sistema operativo. Y sí, sería de sólo lectura, y aunque parezca un
impedimento grande, no lo es tanto, como veremos más adelante.&lt;/p&gt;

&lt;p&gt;Si resulta que ahora necesitamos un tercer entorno, por ejemplo una aplicación web sobre CentOS 7 y
NodeJS 6.9 pero empleando el framework Express 4, podríamos reutilizar las capas anteriores y
nuestra nueva arquitectura quedaría de la siguiente forma:&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-vm-3.png&#34; alt=&#34;Entorno compartido en dos máquinas virtuales&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;¿Vemos la idea?&lt;/p&gt;

&lt;p&gt;¿Y cómo se llama el chico que gestiona todo esto de reutilización de capas en Docker para que no se descontrole
entre distintos entornos virtualizados? El &lt;strong&gt;Union File System&lt;/strong&gt; (UFS). Y no me voy a meter a fondo
con esto, más que nada, porque no lo controlo y no quiero meter la pata. Pero también porque, por el momento,
no me ha hecho falta saber cómo funciona exactamente el UFS para entender Docker y poder trabajar con él.&lt;/p&gt;

&lt;p&gt;Aunque, si estás leyendo esto y eres un experto en este tema, ¡no te cortes! Déjanos algo en los comentarios.&lt;/p&gt;

&lt;p&gt;Por el momento continuamos con el siguiente concepto.&lt;/p&gt;

&lt;h1 id=&#34;las-imágenes&#34;&gt;Las imágenes&lt;/h1&gt;

&lt;p&gt;Una imagen en Docker es &lt;strong&gt;cualquier conjunto vertical y adyacente de capas&lt;/strong&gt;. Es decir, en
la arquitectura de la figura anterior podríamos definir las siguientes imágenes:&lt;/p&gt;


&lt;figure class=&#34;text-center w100&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-im-1.png&#34; alt=&#34;Imágenes posibles en la arquitectura de capas anterior&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;ol&gt;
&lt;li&gt;Una imagen con la capa de CentOS 7.&lt;/li&gt;
&lt;li&gt;Una imagen con la capa de JRE 6 sobre la de CentOS 7.&lt;/li&gt;
&lt;li&gt;Una imagen con la capa de NodeJS 6.9 sobre la de CentOS 7.&lt;/li&gt;
&lt;li&gt;Una imagen con la capa de Express 4, sobre la de NodeJS 6.9, ésta a su vez sobre la de CentOS 7.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Cada una de estas imágenes &lt;strong&gt;servirá como sistema de directorios de nuestras &amp;ldquo;máquinas virtuales&amp;rdquo;&lt;/strong&gt;,
teniendo en cuenta que:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Las imágenes son de &lt;strong&gt;solo lectura&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;El UFS controla, para cada &amp;ldquo;máquina virtual&amp;rdquo;, si alguna de las capas de su imagen está siendo usada por
otra &amp;ldquo;máquina virtual&amp;rdquo;, y si es el caso, &lt;strong&gt;la reutiliza&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;¿Y si ahora queremos ejecutar una aplicación en alguno de nuestros entornos? Fácil: simplemente será
una capa más a añadir encima de nuestra arquitectura. Es decir, los ficheros del aplicación componen
una nueva capa que es gestionada por el UFS. Por ejemplo, para nuestra aplicación Express sobre NodeJS:&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-im-2.png&#34; alt=&#34;Imagen de una aplicación Express sobre NodeJS&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Pero habíamos dicho que nuestras imágenes son de sólo lectura. Entonces, ¿qué pasa cuando nuestra
aplicación realiza una escritura a disco (en un fichero, o en una base de datos)?&lt;/p&gt;

&lt;p&gt;Para responder a esta pregunta hay que introducir el siguiente concepto (y último, por hoy).&lt;/p&gt;

&lt;h1 id=&#34;los-contenedores&#34;&gt;Los contenedores&lt;/h1&gt;

&lt;p&gt;Os habréis dado cuenta del uso de las comillas cuando escribo &amp;ldquo;máquina virtual&amp;rdquo;. Además de porque ya
sabemos que en Docker no existe este concepto exactamente, ya que se trata de una virtualización ligera,
el otro motivo es que en Docker el término que se utiliza es el de &lt;strong&gt;contenedor&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Un contenedor es uno de esos procesos aislados y limitados en recursos de los que hablábamos
&lt;a href=&#34;https://moisesvilar.github.io/post/docker-basics-1/&#34;&gt;en el anterior post&lt;/a&gt; y cuyo sistema de ficheros también
le indicábamos. Como adelantamos arriba, el sistema de ficheros que va a utilizar ese proceso
(o ya podemos llamarlo &lt;em&gt;contenedor&lt;/em&gt;) será la imagen que le indiquemos: la de CentOS 7, la de
CentOS 7 + Java etc.&lt;/p&gt;

&lt;p&gt;Cuando lanzamos un contenedor en Docker, ademas de crear dicho proceso, le añade a su imagen
&lt;strong&gt;una nueva capa de lectura/escritura&lt;/strong&gt; que es donde realizará las modificaciones que se
realicen durante la ejecución del contenedor. Por último, también le asigna una interfaz de
red virtual, para que el contenedor se pueda comunicar con el resto del mundo.&lt;/p&gt;

&lt;p&gt;En esa capa de lectura/escritura es donde el proceso ve una versión concreta de los ficheros
que son modificados. De esta manera, el estado de ejecución entre distintos contenedores que
usen la misma imagen se mantiene independiente entre ambos, y esto permite al UFS poder reutilizar
el resto de capas entre el resto de contenedores que las usen en sus imágenes.&lt;/p&gt;

&lt;p&gt;¿Más o menos queda claro?&lt;/p&gt;

&lt;p&gt;Un contenedor no es más que un proceso aislado y limitado en recursos que sólo ve como
sistema de ficheros lo que la imagen le proporciona, más esa capa de lectura/escritura que
guarda su estado actual.&lt;/p&gt;

&lt;p&gt;Y fijaos: &lt;strong&gt;es un proceso&lt;/strong&gt;. No es una máquina virtual. El lanzamiento de un contenedor es
&lt;strong&gt;rapidísimo&lt;/strong&gt;. Del orden de milisegundos. ¿Cuánto tiempo tardas en iniciar una máquina virtual
con Virtualbox o VMWare? ¿Un par de minutos? ¿Unas cuantas decenas de segundos si tu máquina es potente?
Pues eso.&lt;/p&gt;

&lt;p&gt;Como todos los procesos se pueden pausar, se puede reiniciar y se pueden &lt;em&gt;matar&lt;/em&gt; definitivamente.
Si los pausamos/reiniciamos, la capa de lectura/escritura permanece intacta entre ambos estados. Pero,
si &lt;em&gt;matamos&lt;/em&gt; un contenedor y volvemos a lanzar uno nueva a partir de la misma imagen, la capa
de lectura/escritura habrá desaparecido. ¡Claro, es un contenedor nuevo!&lt;/p&gt;

&lt;p&gt;Así que esta no es la manera adecuada de crear una capa de persistencia usando contenedores Docker.
Pero esto lo veremos en posts futuros cuando presentemos el concepto de volúmenes.&lt;/p&gt;

&lt;h1 id=&#34;conclusiones&#34;&gt;Conclusiones&lt;/h1&gt;

&lt;p&gt;Bueno, la cosa ya se empieza a poner interesante. Hemos visto:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Que Docker usa un sistema de capas, gobernado por el UFS, de tal manera que es capaz de
reutilizarlas si varios contenedores hacen uso de las mismas.&lt;/li&gt;
&lt;li&gt;Que un conjunto de esas capas componen una imagen, que es lo que utilizará Docker para
indicarle qué sistema de ficheros puede ver un determinado contenedor.&lt;/li&gt;
&lt;li&gt;Que los contenedores en Docker no son más que procesos aislados, limitados, con un sistema
de ficheros basado en una imagen, con una capa extra de lectura/escritura que guarda su estado y
con su propia interfaz de red para comunicarse con el resto del mundo.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Ya queda poco para que empecemos a picar comandos, que sé que lo estáis deseando:
crearemos imágenes y lanzaremos contenedores. Pero antes vendrá otro post para definir
unos cuantos conceptos sueltos que me han quedado en el tintero junto con un pequeño tutorial
de cómo instalar Docker en máquinas sin soporte nativo para él.&lt;/p&gt;

&lt;p&gt;¡Nos vemos dentro de nada!&lt;/p&gt;

&lt;p&gt;P.S. Resulta que la imagen de cabecera de este post es el reflejo de un &lt;a href=&#34;http://www.lavozdegalicia.es/noticia/carballo/camarinas/2017/01/10/adios-coidos-costa-da-morte/0003_201701C10C7994.htm&#34;&gt;delito contra el patrimonio natural&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>docker I - lo básico</title>
      <link>https://moisesvilar.github.io/post/docker-basics-1/</link>
      <pubDate>Thu, 05 Jan 2017 09:53:15 +0100</pubDate>
      
      <guid>https://moisesvilar.github.io/post/docker-basics-1/</guid>
      <description>

&lt;p&gt;Hace un par de años, cuando trabajaba en el &lt;a href=&#34;https://citius.usc.es/&#34;&gt;CITIUS&lt;/a&gt;,
&lt;a href=&#34;https://twitter.com/jety_fr&#34;&gt;David Martínez&lt;/a&gt; nos impartió un pequeño seminario de una
herramienta con la que había empezado a trastear hacía poco y lo tenía entusiasmado.&lt;/p&gt;

&lt;p&gt;O bien porque no le presté mucha atención (lo siento, David, no eres tú, soy yo) o bien
porque no supe entender su potencial en aquel momento, pero dejé aquello a un lado y me
desentendí un poco de todo ese &amp;ldquo;nuevo&amp;rdquo; mundo.&lt;/p&gt;

&lt;p&gt;Pero hace un año, más o menos, me llamó la atención el curso de &lt;a href=&#34;http://capside-academy.usefedora.com/p/docker-devops&#34;&gt;Docker Essentials&lt;/a&gt;
alojado en &lt;a href=&#34;http://capside-academy.usefedora.com/&#34;&gt;Capside Academy&lt;/a&gt;. Además, lo impartía el
señor Javi Moreno, un verdadero crack del que tuve el honor de dar mis primeros pasos con Javascript
a partir de un curso que también impartió en el &lt;a href=&#34;https://cntg.xunta.es/web/cnt/home&#34;&gt;CNTG&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Si a Javi le apasionaba Docker, entonces la cosa tenía que ser interesante.&lt;/p&gt;

&lt;p&gt;Así que desempolvé los apuntes que nos había facilitado David y cuando pude sacar algo de tiempo (en realidad, pasaron muchos meses desde que descubrí el curso),
me lo devoré de cabo a rabo. Además, en paralelo, en el podcast de &lt;a href=&#34;http://wedevelopers.com/&#34;&gt;WeDevelopers&lt;/a&gt;
emitieron un capítulo de, exacto&amp;hellip; &lt;a href=&#34;http://wedevelopers.com/2016/11/12/we-developers-046-docker/&#34;&gt;Javi Moreno hablando de Docker!&lt;/a&gt;.
El universo me estaba enviando una señal, no cabía duda.&lt;/p&gt;

&lt;p&gt;Puedo afirmar con una mano en el corazón que desde el primer momento en el que empecé a cacharrear con Docker ya tenía claro que lo
iba a implantar en el trabajo. Ahora mismo lo estamos utilizando para nuestros entornos de desarrollo
y pronto lo tendremos listo para los entornos de preproducción.&lt;/p&gt;

&lt;p&gt;Aunque mi experiencia con Docker no es exhaustiva, ni larga, creo que los conceptos básicos
me han quedado bastante claros, así que voy a intentar plasmarlos aquí con el objetivo de ahorrarle
un par de horas a cualquiera que quiera comenzar con ello.&lt;/p&gt;

&lt;p&gt;Por otro lado, si eres un experto y ves que estoy metiendo la pata hasta el fondo&amp;hellip; vapuléame
en los comentarios! Sin piedad, en serio.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Empezamos!&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;para-qué-se-usa-docker&#34;&gt;¿Para qué se usa Docker?&lt;/h1&gt;

&lt;p&gt;En el 2010, la persona que había gestionado durante trece años el mantenimiento y evolución de
un importante sistema de información de la Xunta de Galicia decidió que era un buen momento
para cambiar de aires. Así que pidió la cuenta y se fué. Y como yo pasaba por allí, &lt;del&gt;me cayó el marrón&lt;/del&gt; me pasaron la responsabilidad.&lt;/p&gt;

&lt;p&gt;Repito: un sistema desarrollado durante trece años. Cuando se picó su primera línea de código,
no existía Google. Cuando yo lo cogí, el iPhone llevaba tres añitos entre nosotros. Os podéis hacer
una idea.&lt;/p&gt;

&lt;p&gt;El caso es que el entorno de desarrollo de dicho sistema era, cuanto menos&amp;hellip; caótico. Mil
dependencias en forma de librerías, algunas open source, otras código propietario, algunas obsoletas,
otras directamente demasiado exóticas o desconocidas&amp;hellip;&lt;/p&gt;

&lt;p&gt;Ignorando temas de mantenibilidad, (que es decir mucho, ya lo sé, pero sólo tenía un añito
de experiencia laboral!), el primer problema con el que me encontré es que dicho entorno de desarrollo
estaba perfectamente instalado y configurado&amp;hellip; en un único equipo. Como en los años 50, cuando
queríamos/necesitábamos realizar una mejora, implementar un cambio, corregir un bug&amp;hellip; un compañero
se movía físicamente a dicho equipo durante los días que hiciese falta (es decir, dejaba su
puesto de trabajo habitual durante días para irse a picar código a otro equipo que no era el suyo, a unas oficinas
que no eran de su empresa y con unos compañeros que no eran los suyos) para implementar la nueva
versión del sistema. Lo compilaba allí mismo, y enviaba los ejecutables por FTP al cabecilla de
turno para que los desplegase.&lt;/p&gt;

&lt;p&gt;Y procurábamos no pensar, por nuestra salud mental, qué pasaría si por alguna razón dicho
equipo ardía o era zapateado escaleras abajo. Todavía se me ponen los pelos de punta.&lt;/p&gt;

&lt;p&gt;Una locura.&lt;/p&gt;

&lt;p&gt;Como comentaba, era un sistema bastante importante (aunque no lo parezca) así que las presiones
por tener implementadas mejoras y correcciones eran prácticamente constantes todo el año. Estaba
descartada la idea de hacer un trabajo &amp;ldquo;forense&amp;rdquo; e intentar replicar el estado de dicho equipo de
desarrollo en otra máquina. Así que opté por utilizar una herramienta de VMWare
(el &lt;a href=&#34;http://www.vmware.com/products/converter.html&#34;&gt;vCenter Converter&lt;/a&gt;) que, básicamente,
escaneaba un sistema de ficheros entero alojado en una máquina física y lo convertía en una máquina
virtual. De esta manera, virtualicé (a cañonazos) el equipo de desarrollo, me lo metí en una memoria
externa y, oye, por lo menos podíamos dormir tranquilos: ya teníamos una copia virtual del entorno
de desarrollo, que podíamos ejecutar donde quisiéramos (siempre y cuando el equipo anfitrión
fuera lo suficientemente potente) y los desarrolladores ya no tenían que estar trabajando entre dos
sitios distintos. Quiero pensar que su calidad de vida incrementó enteros en aquel momento.&lt;/p&gt;

&lt;p&gt;¿Por qué os cuento esta historia? Porque Docker te permite, entre otras cosas,
&lt;strong&gt;replicar exactamente&lt;/strong&gt; el entorno de ejecución de un proyecto, de una manera muchísimo más
eficiente y rápida que la que buenamente implementé yo con el vCenter Converter. Eso sí, con matices
que iremos viendo paulatinamente.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;En realidad, si no empiezas tu proyecto usando Docker, puede ser bastante complicado replicar su
 entorno de ejecución a posteriori. Es más, en la historia que os cuento, sería como mínimo una tarea complicada y tediosa.
 Pero estas cosas las comentaremos más adelante en posts futuros.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Imaginad que puedo desplegar un entorno de ejecución de cualquier sistema/aplicación en un tiempo
ridículo (del orden de milisegundos) y siendo lo más eficiente posible en el uso de recursos. Pues eso es Docker.&lt;/p&gt;

&lt;p&gt;Partiendo de esto, podéis intuir que el paso de desarrollo a producción es indoloro (adiós a
aquello de &lt;em&gt;¡en mi máquina funcionaba!&lt;/em&gt;). En todos los escenarios (desarrollo, testing, preproducción, producción&amp;hellip;) tenemos exactamente
el mismo entorno (el mismo sistema operativo, la misma base de datos, las mismas librerías&amp;hellip; todo
en las versiones exactas). El margen para los problemas se estrecha bastante.&lt;/p&gt;

&lt;h1 id=&#34;todo-eso-está-muy-bien-pero-cómo-funciona&#34;&gt;Todo eso está muy bien, pero ¿cómo funciona?&lt;/h1&gt;

&lt;p&gt;En realidad, la tecnología que está en las tripas de Docker no es el último grito precisamente.
Emplea herramientas que llevan con nosotros muchos, muchos años. Si eres un experto en entornos
Unix, seguramente te suenen. Yo no lo soy, así que me sonaban vagamente cuando empecé con Docker.&lt;/p&gt;

&lt;p&gt;En Unix tenemos desde hace muchos años las siguientes funcionalidades:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://es.wikipedia.org/wiki/Chroot&#34;&gt;chroot&lt;/a&gt;: básicamente le indica a un proceso que su
sistema de ficheros empieza donde tú le digas. Es decir, cambias la raíz del sistema de ficheros
del proceso (de ahí su nombre, &lt;em&gt;change root&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cgroups&#34;&gt;cgroups&lt;/a&gt;: se utiliza para limitar en recursos la
ejecución de un proceso: memoria, ancho de banda, núcleos etc categorizando los procesos en diferentes &lt;em&gt;control groups&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://man7.org/linux/man-pages/man7/namespaces.7.html&#34;&gt;namespaces&lt;/a&gt;: útiles para aislar un proceso
del resto de procesos. Es decir, poder hacerle creer a un proceso que es el único que se está
ejecutando en toda la máquina.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pues perfecto, si ejecutamos un proceso aislado, limitado en recursos y le decimos que la raíz
de su sistema de ficheros está en un directorio donde tenemos almacenados casualmente los binarios de nuestro
entorno de ejecución (sistema operativo, base de datos, servidor de aplicaciones etc), &lt;em&gt;alehop!&lt;/em&gt;,
&lt;strong&gt;acabamos de virtualizar dicho entorno a nivel de sistema operativo&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Y esto es la idea principal de Docker: virtualización ligera a nivel de sistema operativo.
Usando procesos pequeños y rápidos en vez de pesadas máquinas virtuales. Y siendo muy eficientes
en los binarios que componen nuestro entorno de ejecución, como veremos en futuros posts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Estas son las tripas de Docker. La verdad detrás del truco, que necesitamos saber para no
caer en lo que comentaba el bueno de Arthur C. Clarke: &lt;em&gt;cualquier tecnología lo suficientemente
avanzada es indistinguible de la magia&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Pero para nuestro día a día, lo único que tenemos que tener claro es que Docker maneja la siguiente
arquitectura:&lt;/p&gt;


&lt;figure class=&#34;text-center w100&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-architecture.png&#34; alt=&#34;arquitectura de docker&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Es decir, tenemos un &lt;strong&gt;intérprete de Docker&lt;/strong&gt;, el &lt;em&gt;docker client&lt;/em&gt;, que se comunica con el sistema Docker
(el &lt;em&gt;docker server&lt;/em&gt;) a través de una API REST bajo HTTPS cuyo punto de acceso está implementado
en el proceso &lt;em&gt;docker agent&lt;/em&gt; que se ejecuta en background.&lt;/p&gt;

&lt;p&gt;Con cada comando que ejecutamos en Docker, por ejemplo:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -ti alpine /bin/sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;en realidad estamos invocando una o varias peticiones HTTPS a dicha API REST. ¡Incluso podríamos
comunicarnos con ella directamente empleando cURL por ejemplo!&lt;/p&gt;

&lt;p&gt;Es el &lt;em&gt;docker agent&lt;/em&gt; el encargado de procesar dicha llamada y comunicarse con el núcleo de Docker para que gestione la virtualización
de nuestros entornos utilizando las tres herramientas Unix que veíamos más arriba.&lt;/p&gt;

&lt;p&gt;Por último, decir que la máquina anfitrión, desde el punto de vista de Docker, es aquella que ejecuta
directamente el &lt;em&gt;docker server&lt;/em&gt;. Y para ello, el sistema operativo anfitrión debe &lt;strong&gt;soportar Docker de forma
nativa&lt;/strong&gt;. ¿Esto qué significa? Pues sencillamente, que tiene que implementar algo parecido a los &lt;em&gt;chroots&lt;/em&gt;,
&lt;em&gt;cgroups&lt;/em&gt; y &lt;em&gt;namespaces&lt;/em&gt; que veíamos más arriba. Es decir, tiene que darle las herramientas necesarias a Docker
para que éste haga su magia.&lt;/p&gt;

&lt;p&gt;Por el momento, basta con decir que cualquier sistema basado en Unix (Linux, MacOS) tiene soporte nativo de Docker. Y Windows 10 lo tiene en su versión
Professional, aunque he de decir que mi experiencia por el momento me dice que está bastante verde. Para el resto de
sistemas operativos (Windows 10 Home, Windows 8.1, Windows 7&amp;hellip;) habrá que utilizar un pequeño atajo para poder trabajar con Docker. ¡Pero no adelantemos acontecimientos!
Simplemente sabed que se puede.&lt;/p&gt;

&lt;h1 id=&#34;conclusiones&#34;&gt;Conclusiones&lt;/h1&gt;

&lt;p&gt;Lo sé. No ha sido un post muy exhaustivo, no tenemos código, ni comandos, ni sabemos cómo trabajar con Docker. Pero me
parece interesante asentar bien los conceptos básicos para lo que viene después. Lo que hemos visto aquí:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Docker te permite replicar entornos de ejecución en base a virtualización ligera a nivel de sistema operativo. Eso nos permite terminar de raíz con el problema de &lt;em&gt;¡en mi máquina funciona!&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Para realizar esa virtualización ligera, se apoya en tres herramientas que tenemos en Unix desde casi siempre: chroot, cgroups y namespaces, creando procesos aislados, limitados en recursos y que manejan un sistema de archivos que nosotros les decimos.&lt;/li&gt;
&lt;li&gt;Docker está implementado como una API REST sobre HTTPS. Cuando ejecutamos un comando, lo que realmente hacemos es invocar un método de esa API REST y Docker, tras el telón, hace su magia.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Por último, os invito de nuevo a escuchar el podcast de &lt;a href=&#34;http://wedevelopers.com/2016/11/12/we-developers-046-docker/&#34;&gt;Javi Moreno hablando de Docker!&lt;/a&gt; en WeDevelopers.
Y a realizar su curso de &lt;a href=&#34;http://capside-academy.usefedora.com/p/docker-devops&#34;&gt;Docker Essentials&lt;/a&gt; en Capside-Academy. Son sólo 20€ y os aseguro que estarán
bien invertidos. Así a todo, de vez en cuando escupen algún código promocional a través de &lt;a href=&#34;https://twitter.com/capside&#34;&gt;su cuenta de Twitter&lt;/a&gt;.
También es altamente recomendable seguir a &lt;a href=&#34;https://twitter.com/ciberado&#34;&gt;Javi en Twitter&lt;/a&gt; o poner su blog &lt;a href=&#34;https://programar.cloud/&#34;&gt;Programar en Cloud&lt;/a&gt; en tu lector de RSS favorito. Habla de Docker,
microservicios, testing&amp;hellip; y un montón de cosas interesantes.&lt;/p&gt;

&lt;p&gt;¡Nos vemos en el siguiente post!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>bienvenida</title>
      <link>https://moisesvilar.github.io/post/bienvenida/</link>
      <pubDate>Wed, 04 Jan 2017 13:43:24 +0100</pubDate>
      
      <guid>https://moisesvilar.github.io/post/bienvenida/</guid>
      <description>

&lt;h1 id=&#34;quién-soy&#34;&gt;Quién soy&lt;/h1&gt;

&lt;figure&gt;
  &lt;img src=&#34;https://moisesvilar.github.io//images/me.jpg#small-image&#34; alt=&#34;bienvenida /images/me.jpg#small-image&#34;&gt;
  
&lt;/figure&gt;


&lt;p&gt;Mi nombre es Moisés Vilar. Soy desarrollador desde los 12 años y desde hace 9 me pagan por ello.&lt;/p&gt;

&lt;p&gt;En este blog intentaré escribir sobre las cosas que fui aprendiendo durante mi carrera profesional pero también sobre temas
que estoy empezando a descubrir ahora.&lt;/p&gt;

&lt;p&gt;En definitiva, hablaremos sobre desarrollo web, Javascript, HTML5, NodeJS, MongoDB, Docker&amp;hellip;&lt;/p&gt;

&lt;p&gt;Cualquier consulta, duda, sugerencia, molestia, queja, dolor&amp;hellip; no te cortes en dejarme un comentario en este blog
o contactar conmigo a través de Twitter.&lt;/p&gt;

&lt;p&gt;
&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/keep-calm-and-write-some-code.png#medium-image&#34; alt=&#34;Keep calm and write some code&#34; /&gt;
    
    
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bienvenidos!&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>