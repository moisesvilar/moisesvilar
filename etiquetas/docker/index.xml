<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on Write some code!</title>
    <link>https://moisesvilar.github.io/etiquetas/docker/index.xml</link>
    <description>Recent content in Docker on Write some code!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es-ES</language>
    <copyright>&amp;copy; Esta obra está bajo una &lt;a target=&#39;_blank&#39; rel=&#39;license&#39; href=&#39;http://creativecommons.org/licenses/by/4.0/&#39;&gt;Licencia Creative Commons Atribución 4.0 Internacional&lt;/a&gt;.</copyright>
    <atom:link href="https://moisesvilar.github.io/etiquetas/docker/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>docker III - docker hub, docker machine</title>
      <link>https://moisesvilar.github.io/post/docker-concepts-3/</link>
      <pubDate>Thu, 12 Jan 2017 20:49:11 +0100</pubDate>
      
      <guid>https://moisesvilar.github.io/post/docker-concepts-3/</guid>
      <description>

&lt;p&gt;En este post veremos los últimos acordes antes de ponernos a tocar la sinfonía. Lo dividiré en dos partes.
En la primera, describiremos dos conceptos que nos serán útiles a la hora de trabajar con Docker.
En la segunda, haremos un pequeño tutorial de cómo instalar Docker en sistemas sin soporte nativo.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Vamos allá!&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;últimos-conceptos-por-ahora&#34;&gt;Últimos conceptos&amp;hellip; por ahora&lt;/h1&gt;

&lt;p&gt;Veremos dos de ellos: el Docker Hub y la Docker machine.&lt;/p&gt;

&lt;h2 id=&#34;docker-hub&#34;&gt;Docker Hub&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://moisesvilar.github.io/post/docker-layers-2/&#34;&gt;En el anterior post&lt;/a&gt; vimos el concepto de &lt;strong&gt;imágenes&lt;/strong&gt;
como un conjunto de capas que forman los binarios de nuestros entornos (por ejemplo, CentOS 7 +
NodeJS 6.9). Pues bien, estas imágenes pueden ser subidas a un repositorio gestionado por
los chicos de Docker. Esto es el Docker Hub.&lt;/p&gt;

&lt;p&gt;Allí encontrarás una enorme (muy enorme) cantidad de imágenes ya creadas por otras personas
alrededor del mundo. Algunas de ellas tienen la etiqueta de &lt;em&gt;oficial&lt;/em&gt;: han sido creadas y son
mantenidas por los chicos que están detrás del desarrollo de dichos binarios. Por ejemplo,
puedes encontrar imágenes oficiales para entornos con NodeJS.&lt;/p&gt;

&lt;p&gt;Al Docker Hub se puede acceder a través de la siguiente URL: &lt;a href=&#34;https://hub.docker.com/&#34;&gt;https://hub.docker.com/&lt;/a&gt;.
Hace falta registrarse, pero es gratuíto y no tardarás más de un minuto.&lt;/p&gt;

&lt;p&gt;Una vez lo hayas hecho, en el cuadro de búsqueda puedes probar a introducir &amp;ldquo;node&amp;rdquo;. El primer resultado
está catalogado como &lt;em&gt;oficial&lt;/em&gt;. Si lo inspeccionamos, veremos que esta imagen está disponible
con varios &lt;em&gt;tags&lt;/em&gt;: para la versión 7.4, 6.9, 4.7&amp;hellip;&lt;/p&gt;

&lt;p&gt;Fijaos en aquellos &lt;em&gt;tags&lt;/em&gt; que terminan con &lt;em&gt;alpine&lt;/em&gt; y buscad dicha imagen en el buscador. Alpine
es una distribución de Linux que viene con lo básico y que ocupa la friolera de &lt;strong&gt;2 MB&lt;/strong&gt;. Comparadlo
con el peso de la imagen de CentOS (70MB): si montamos nuestros entornos a partir de Alpine
(siempre y cuando una decisión de diseño nos impida hacerlo), montando sobre él todo lo que necesitemos
(un Apache, una JVM etc.) nos acabamos de librar de 68MB de &lt;em&gt;overhead&lt;/em&gt; y nuestras imágenes serán
muy livianas.&lt;/p&gt;

&lt;p&gt;Fijaos ahora, entrando en cualquier imagen, en el recuadro de la derecha, titulado &lt;em&gt;Docker Pull Command&lt;/em&gt;:
exacto, el Docker Hub está implementado como un SaaS y podremos descargar imágenes a través de su API.
Concretamente, el comando &lt;em&gt;docker pull&lt;/em&gt; nos permitirá hacer esto sobre línea de comandos.&lt;/p&gt;

&lt;p&gt;Docker Hub, como hemos dicho, es gratuíto y su modelo de negocio es muy parecido a Github: con tu
cuenta gratuíta, todas tus imágenes serán públicas. Si deseas que sean privadas, tienes que pasar
por caja.&lt;/p&gt;

&lt;h2 id=&#34;docker-machine&#34;&gt;Docker machine&lt;/h2&gt;

&lt;p&gt;Como hemos dicho anteriormente, Docker necesita que el sistema operativo de la máquina anfitrión
tenga la capacidad de utilizar chroot, cgroups y namespaces. Esto lo cumple cualquier sistema operativo
basado en Unix (Linux o MacOS), Windows Server y Windows 10 Professional.&lt;/p&gt;

&lt;p&gt;Pero para versiones anteriores hay que instalar el paquete conocido como &lt;em&gt;Docker Toolbox&lt;/em&gt;
(lo veremos en la siguiente sección).&lt;/p&gt;

&lt;p&gt;Dentro de este paquete se encuentra la &lt;em&gt;Docker machine&lt;/em&gt;: es una máquina virtual ligera (~20MB)
basada en Linux. Una vez arrancada, dentro de ella tendremos soporte nativo para Docker y podremos
ejecutar nuestros comandos para descargar imágenes, lanzar contenedores etc.&lt;/p&gt;

&lt;p&gt;Fijaos que, en este escenario, para Docker el &lt;em&gt;host&lt;/em&gt; ya no será nuestra máquina física, sino
la Docker machine.&lt;/p&gt;

&lt;h1 id=&#34;instalación-de-docker-en-sistemas-sin-soporte-nativo&#34;&gt;Instalación de Docker en sistemas sin soporte nativo&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Un consejo: a partir de aquí os recomendiendo que leais esto desde un PC y que intentéis seguir los pasos a medida que vayáis leyendo.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;En primer lugar, necesitamos descargarnos el paquete &lt;a href=&#34;https://www.docker.com/products/docker-toolbox&#34;&gt;Docker Toolbox&lt;/a&gt;.
Con él, entre otras herramientas, nos vendrá la Docker machine y Virtualbox, que es el motor de virtualización
que utilizaremos para crear nuestra pequeña máquina virtual Linux que &lt;strong&gt;sí&lt;/strong&gt; tenga soporte nativo para Docker.&lt;/p&gt;

&lt;p&gt;Ahora, tenemos dos caminos. El más fácil, es hacer doble click en el acceso directo que tendremos en el escritorio
(si así lo hemos marcado durante la instalación) y esto nos creará la máquina virtual de la que hablamos.&lt;/p&gt;

&lt;p&gt;Pero como sé que os gusta el picar comandos y el terminal, lo haremos de esta manera.&lt;/p&gt;

&lt;p&gt;Abrid un terminal, cmd o como queráis llamarle. Y por favor, no uséis el nativo de Windows. Descargaros algo como
&lt;a href=&#34;https://conemu.github.io/&#34;&gt;ConEmu&lt;/a&gt; o &lt;a href=&#34;http://cmder.net/&#34;&gt;cmder&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Si picamos&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine create -d virtualbox default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;crearemos una máquina virtual de nombre &lt;em&gt;default&lt;/em&gt; utilizando el driver para &lt;em&gt;Virtualbox&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Una vez finalizada la ejecución de este comando, si picamos&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine ls
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;veremos un listado de nuestras máquinas virtuales creadas:&lt;/p&gt;


&lt;figure class=&#34;w70 text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-3-commands-1.png&#34; alt=&#34;Resultados de docker-machine ls&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Resultados de docker-machine ls&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Por el momento, sólo fijaos en la columna &lt;em&gt;STATE&lt;/em&gt;, que nos indica que la máquina está ejecutándose.&lt;/p&gt;

&lt;p&gt;Si ahora hacemos:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine ssh default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;estableceremos una conexión SSH con nuestra máquina. Ahora ya estamos dentro de una máquina con soporte nativo para Docker. Concretamente, una distribución
Linux (llamada &lt;em&gt;Boot2Docker&lt;/em&gt;) superligera para que el impacto en nuestro equipo sea mínimo.&lt;/p&gt;

&lt;p&gt;Antes de terminar, vamos a ejecutar un par de comandos más:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker login
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Esta es la primera vez que vamos a ejecutar el programa &lt;em&gt;docker&lt;/em&gt;. Tened siempre presente que lo que hace este ejecutable es conectarse a través de
HTTPS al docker-agent e invocar los métodos de su API REST.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Con este comando podemos hacer login en el &lt;em&gt;Docker hub&lt;/em&gt; para poder descargar nuevas imágenes. Nos pedirá nuestro nombre de usuario y contraseña, y ya
los tendremos porque ya hemos creado la cuenta al comienzo de este post, ¿verdad? ¿VERDAD? ;)&lt;/p&gt;

&lt;p&gt;Ahora vamos a buscar imágenes a través del SaaS que proporciona &lt;em&gt;Docker hub&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker search alpine
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nos devolverá el listado de imágenes cuyo nombre, descripción&amp;hellip; contenga la cadena &lt;em&gt;alpine&lt;/em&gt;. Podéis comprobar que son los mismos resultados que obtuvimos
en la primera parte de este post, cuando lo buscamos manualmente a través de la interfaz web del &lt;em&gt;Docker hub&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Muy bien, pues vamos a descargarnos la imagen oficial para alpine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull alpine:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Con &lt;em&gt;:latest&lt;/em&gt;, le estamos indicando que se descargue la imagen cuya &lt;strong&gt;etiqueta&lt;/strong&gt; sea &lt;em&gt;latest&lt;/em&gt;. Este es el comportamiento por defecto si no especificamos
etiqueta.&lt;/p&gt;

&lt;p&gt;Tardará como cosa de dos pestañeos (ocupa 4MB, ¿recordáis?), así que tendréis que estar atentos para daros cuenta de que en algún momento la salida por pantalla nos pone algo como
&lt;em&gt;Pulling layer&lt;/em&gt;. ¡Exacto! Al descargar la imagen, nos estamos descargando todas las capas que la componen. En este caso, la imagen de alpine sólo cuenta con
una capa, la que contiene los binarios de este sistema operativo.&lt;/p&gt;

&lt;p&gt;Para listar las imágenes que tenemos descargadas en nuestro sistema:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker images
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Veremos aquí nuestra imagen alpine recién descargada. Fijaos en la columna &lt;em&gt;SIZE&lt;/em&gt;. 3.984MB. Veis que no os mentía: todo un Linux funcional en menos de 4MB.&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-3-commands-2.png&#34; alt=&#34;Salida del comando docker images, con nuestra imagen alpine de apenas 4MB :)&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Salida del comando docker images, con nuestra imagen alpine de apenas 4MB :)&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h1 id=&#34;conclusiones&#34;&gt;Conclusiones&lt;/h1&gt;

&lt;p&gt;En este pequeño post hemos visto los conceptos de &lt;em&gt;Docker hub&lt;/em&gt; y &lt;em&gt;Docker machine&lt;/em&gt;. Hemos instalado Docker en un sistema no nativo (Windows 10 Home, por ejemplo) y ¡ole! hemos
picado nuestros primeros comandos para &lt;em&gt;loguearnos&lt;/em&gt; en el Docker hub, buscar imágenes, descargarlas y listar las que tengamos descargadas en nuestra máquina.&lt;/p&gt;

&lt;p&gt;En el siguiente post nos pondremos serios: empezamos a lanzar contenedores.&lt;/p&gt;

&lt;p&gt;¡Nos vemos en nada!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>docker II - capas e imágenes</title>
      <link>https://moisesvilar.github.io/post/docker-layers-2/</link>
      <pubDate>Tue, 10 Jan 2017 19:51:45 +0100</pubDate>
      
      <guid>https://moisesvilar.github.io/post/docker-layers-2/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://moisesvilar.github.io/post/docker-basics-1/&#34;&gt;En el anterior post&lt;/a&gt; vimos que una de las herramientas heredadas de Unix que utilizaba Docker eran los chroot.
Con ellos, podíamos establecer para un proceso &lt;strong&gt;en qué directorio comenzaba su sistema de ficheros&lt;/strong&gt;, su &lt;em&gt;carpeta raíz&lt;/em&gt;. También dijimos que, en la gestión de dicho sistema de ficheros,
Docker era bastante eficiente.&lt;/p&gt;

&lt;p&gt;En este post veremos en qué consiste esta eficiencia y cómo la consigue Docker.&lt;/p&gt;

&lt;h1 id=&#34;las-capas&#34;&gt;Las capas&lt;/h1&gt;

&lt;p&gt;Imaginémonos que tenemos dos entornos de ejecución para dos aplicaciones.
Ambos se ejecutan sobre el sistema operativo CentOS 7. Pero la primera,
es una aplicación basada en la API 6 de Java. Porque somos tipos duros. Y la segunda es
una aplicación NodeJS 6.9.&lt;/p&gt;

&lt;p&gt;Vamos a hacer el ejercicio mental de montar sendos entornos de ejecución en dos máquinas virtuales.&lt;/p&gt;

&lt;p&gt;Para la &lt;strong&gt;primera máquina virtual&lt;/strong&gt;, la que reproduce el entorno de ejecución de la aplicación Java,
tendremos que instalar:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;El sistema operativo CentOS 7.&lt;/li&gt;
&lt;li&gt;La máquina virtual de Java para la versión 6 de su API.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Para la &lt;strong&gt;segunda máquina virtual&lt;/strong&gt;, la de la aplicación NodeJS:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;El sistema operativo CentOS 7 &lt;em&gt;again&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;El servidor NodeJS en su versión 6.9.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Fijaos en el primer punto de ambas máquinas, el sistema operativo CentOS 7.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;¿Todos los ficheros binarios que componen dicho sistema operativo están duplicados en ambas máquinas?&lt;/strong&gt;
Por supuesto que sí.&lt;/p&gt;

&lt;p&gt;Tendríamos algo como esto:&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-vm-1.png&#34; alt=&#34;Entorno en cada máquina virtual&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Entornos independientes (y dupicados) en dos máquinas virtuales&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Esto no parece que sea muy eficiente. Es decir, ambas máquinas duplican &lt;strong&gt;exactamente&lt;/strong&gt; los mismos
binarios para el sistema operativo.&lt;/p&gt;

&lt;p&gt;¿Qué pasaría si dichos binarios se pudiesen &lt;strong&gt;reutilizar&lt;/strong&gt; entre ambas máquinas? En este escenario,
ganaríamos eficiencia, ya que ambas máquinas compartirían los ficheros del sistema operativo
(al fin y al cabo, es el mismo para ambos entornos). La única condición que necesitaríamos es que
dichos binarios fueran de &lt;strong&gt;sólo lectura&lt;/strong&gt;, para evitar que una escritura de la primera máquina
cambiase el entorno de la segunda y ésta se fuese al garete.&lt;/p&gt;

&lt;p&gt;En este segundo caso tendríamos:&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-vm-2.png&#34; alt=&#34;Entorno compartido en dos máquinas virtuales&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Entorno teórico de dos máquinas virtuales que comparten y reutilizan partes del mismo, en este caso, el sistema operativo&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Bien, ahora bauticemos las cosas. Resulta que a un conjunto de binarios (por ejemplo, los que
componen el sistema operativo CentOS 7) se le denomina &lt;strong&gt;una capa&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Este concepto de &lt;strong&gt;capas reutilizables&lt;/strong&gt; es lo que emplea Docker para ganar eficiencia entre
las &amp;ldquo;máquinas virtuales&amp;rdquo; (con todas las comillas que queráis) que gestiona. Es decir, la arquitectura
de capas que emplearía Docker para modelizar los entornos del ejemplo sería la de la segunda figura,
reutilizando la capa del sistema operativo. Y sí, sería de sólo lectura, y aunque parezca un
impedimento grande, no lo es tanto, como veremos más adelante.&lt;/p&gt;

&lt;p&gt;Si resulta que ahora necesitamos un tercer entorno, por ejemplo una aplicación web sobre CentOS 7 y
NodeJS 6.9 pero empleando el framework Express 4, podríamos reutilizar las capas anteriores y
nuestra nueva arquitectura quedaría de la siguiente forma:&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-vm-3.png&#34; alt=&#34;Entorno compartido en dos máquinas virtuales&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Entornos de tres máquinas virtuales que comparten y reutilizan partes: sistema operativo, servidor de aplicaciones etc.&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;¿Vemos la idea?&lt;/p&gt;

&lt;p&gt;¿Y cómo se llama el chico que gestiona todo esto de reutilización de capas en Docker para que no se descontrole
entre distintos entornos virtualizados? El &lt;strong&gt;Union File System&lt;/strong&gt; (UFS). Y no me voy a meter a fondo
con esto, más que nada, porque no lo controlo y no quiero meter la pata. Pero también porque, por el momento,
no me ha hecho falta saber cómo funciona exactamente el UFS para entender Docker y poder trabajar con él.&lt;/p&gt;

&lt;p&gt;Aunque, si estás leyendo esto y eres un experto en este tema, ¡no te cortes! Déjanos algo en los comentarios.&lt;/p&gt;

&lt;p&gt;Por el momento continuamos con el siguiente concepto.&lt;/p&gt;

&lt;h1 id=&#34;las-imágenes&#34;&gt;Las imágenes&lt;/h1&gt;

&lt;p&gt;Una imagen en Docker es &lt;strong&gt;cualquier conjunto vertical y adyacente de capas&lt;/strong&gt;. Es decir, en
la arquitectura de la figura anterior podríamos definir las siguientes imágenes:&lt;/p&gt;


&lt;figure class=&#34;text-center w100&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-im-1.png&#34; alt=&#34;Imágenes posibles en la arquitectura de capas anterior&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Imágenes posibles en una arquitectura de capas&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;ol&gt;
&lt;li&gt;Una imagen con la capa de CentOS 7.&lt;/li&gt;
&lt;li&gt;Una imagen con la capa de JRE 6 sobre la de CentOS 7.&lt;/li&gt;
&lt;li&gt;Una imagen con la capa de NodeJS 6.9 sobre la de CentOS 7.&lt;/li&gt;
&lt;li&gt;Una imagen con la capa de Express 4, sobre la de NodeJS 6.9, ésta a su vez sobre la de CentOS 7.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Cada una de estas imágenes &lt;strong&gt;servirá como sistema de directorios de nuestras &amp;ldquo;máquinas virtuales&amp;rdquo;&lt;/strong&gt;,
teniendo en cuenta que:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Las imágenes son de &lt;strong&gt;solo lectura&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;El UFS controla, para cada &amp;ldquo;máquina virtual&amp;rdquo;, si alguna de las capas de su imagen está siendo usada por
otra &amp;ldquo;máquina virtual&amp;rdquo;, y si es el caso, &lt;strong&gt;la reutiliza&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;¿Y si ahora queremos ejecutar una aplicación en alguno de nuestros entornos? Fácil: simplemente será
una capa más a añadir encima de nuestra arquitectura. Es decir, los ficheros del aplicación componen
una nueva capa que es gestionada por el UFS. Por ejemplo, para nuestra aplicación Express sobre NodeJS:&lt;/p&gt;


&lt;figure class=&#34;text-center&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-2-im-2.png&#34; alt=&#34;Imagen de una aplicación Express sobre NodeJS&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Imagen de una aplicación Express sobre NodeJS&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Pero habíamos dicho que nuestras imágenes son de sólo lectura. Entonces, ¿qué pasa cuando nuestra
aplicación realiza una escritura a disco (en un fichero, o en una base de datos)?&lt;/p&gt;

&lt;p&gt;Para responder a esta pregunta hay que introducir el siguiente concepto (y último, por hoy).&lt;/p&gt;

&lt;h1 id=&#34;los-contenedores&#34;&gt;Los contenedores&lt;/h1&gt;

&lt;p&gt;Os habréis dado cuenta del uso de las comillas cuando escribo &amp;ldquo;máquina virtual&amp;rdquo;. Además de porque ya
sabemos que en Docker no existe este concepto exactamente, ya que se trata de una virtualización ligera,
el otro motivo es que en Docker el término que se utiliza es el de &lt;strong&gt;contenedor&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Un contenedor es uno de esos procesos aislados y limitados en recursos de los que hablábamos
&lt;a href=&#34;https://moisesvilar.github.io/post/docker-basics-1/&#34;&gt;en el anterior post&lt;/a&gt; y cuyo sistema de ficheros también
le indicábamos. Como adelantamos arriba, el sistema de ficheros que va a utilizar ese proceso
(o ya podemos llamarlo &lt;em&gt;contenedor&lt;/em&gt;) será la imagen que le indiquemos: la de CentOS 7, la de
CentOS 7 + Java etc.&lt;/p&gt;

&lt;p&gt;Cuando lanzamos un contenedor en Docker, ademas de crear dicho proceso, le añade a su imagen
&lt;strong&gt;una nueva capa de lectura/escritura&lt;/strong&gt; que es donde realizará las modificaciones que se
realicen durante la ejecución del contenedor. Por último, también le asigna una interfaz de
red virtual, para que el contenedor se pueda comunicar con el resto del mundo.&lt;/p&gt;

&lt;p&gt;En esa capa de lectura/escritura es donde el proceso ve una versión concreta de los ficheros
que son modificados. De esta manera, el estado de ejecución entre distintos contenedores que
usen la misma imagen se mantiene independiente entre ambos, y esto permite al UFS poder reutilizar
el resto de capas entre el resto de contenedores que las usen en sus imágenes.&lt;/p&gt;

&lt;p&gt;¿Más o menos queda claro?&lt;/p&gt;

&lt;p&gt;Un contenedor no es más que un proceso aislado y limitado en recursos que sólo ve como
sistema de ficheros lo que la imagen le proporciona, más esa capa de lectura/escritura que
guarda su estado actual.&lt;/p&gt;

&lt;p&gt;Y fijaos: &lt;strong&gt;es un proceso&lt;/strong&gt;. No es una máquina virtual. El lanzamiento de un contenedor es
&lt;strong&gt;rapidísimo&lt;/strong&gt;. Del orden de milisegundos. ¿Cuánto tiempo tardas en iniciar una máquina virtual
con Virtualbox o VMWare? ¿Un par de minutos? ¿Unas cuantas decenas de segundos si tu máquina es potente?
Pues eso.&lt;/p&gt;

&lt;p&gt;Como todos los procesos se pueden pausar, se puede reiniciar y se pueden &lt;em&gt;matar&lt;/em&gt; definitivamente.
Si los pausamos/reiniciamos, la capa de lectura/escritura permanece intacta entre ambos estados. Pero,
si &lt;em&gt;matamos&lt;/em&gt; un contenedor y volvemos a lanzar uno nueva a partir de la misma imagen, la capa
de lectura/escritura habrá desaparecido. ¡Claro, es un contenedor nuevo!&lt;/p&gt;

&lt;p&gt;Así que esta no es la manera adecuada de crear una capa de persistencia usando contenedores Docker.
Pero esto lo veremos en posts futuros cuando presentemos el concepto de volúmenes.&lt;/p&gt;

&lt;h1 id=&#34;conclusiones&#34;&gt;Conclusiones&lt;/h1&gt;

&lt;p&gt;Bueno, la cosa ya se empieza a poner interesante. Hemos visto:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Que Docker usa un sistema de capas, gobernado por el UFS, de tal manera que es capaz de
reutilizarlas si varios contenedores hacen uso de las mismas.&lt;/li&gt;
&lt;li&gt;Que un conjunto de esas capas componen una imagen, que es lo que utilizará Docker para
indicarle qué sistema de ficheros puede ver un determinado contenedor.&lt;/li&gt;
&lt;li&gt;Que los contenedores en Docker no son más que procesos aislados, limitados, con un sistema
de ficheros basado en una imagen, con una capa extra de lectura/escritura que guarda su estado y
con su propia interfaz de red para comunicarse con el resto del mundo.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Ya queda poco para que empecemos a picar comandos, que sé que lo estáis deseando:
crearemos imágenes y lanzaremos contenedores. Pero antes vendrá otro post para definir
unos cuantos conceptos sueltos que me han quedado en el tintero junto con un pequeño tutorial
de cómo instalar Docker en máquinas sin soporte nativo para él.&lt;/p&gt;

&lt;p&gt;¡Nos vemos dentro de nada!&lt;/p&gt;

&lt;p&gt;P.S. Resulta que la imagen de cabecera de este post es el reflejo de un &lt;a href=&#34;http://www.lavozdegalicia.es/noticia/carballo/camarinas/2017/01/10/adios-coidos-costa-da-morte/0003_201701C10C7994.htm&#34;&gt;delito contra el patrimonio natural&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>docker I - lo básico</title>
      <link>https://moisesvilar.github.io/post/docker-basics-1/</link>
      <pubDate>Thu, 05 Jan 2017 09:53:15 +0100</pubDate>
      
      <guid>https://moisesvilar.github.io/post/docker-basics-1/</guid>
      <description>

&lt;p&gt;Hace un par de años, cuando trabajaba en el &lt;a href=&#34;https://citius.usc.es/&#34;&gt;CITIUS&lt;/a&gt;,
&lt;a href=&#34;https://twitter.com/jety_fr&#34;&gt;David Martínez&lt;/a&gt; nos impartió un pequeño seminario de una
herramienta con la que había empezado a trastear hacía poco y lo tenía entusiasmado.&lt;/p&gt;

&lt;p&gt;O bien porque no le presté mucha atención (lo siento, David, no eres tú, soy yo) o bien
porque no supe entender su potencial en aquel momento, pero dejé aquello a un lado y me
desentendí un poco de todo ese &amp;ldquo;nuevo&amp;rdquo; mundo.&lt;/p&gt;

&lt;p&gt;Pero hace un año, más o menos, me llamó la atención el curso de &lt;a href=&#34;http://capside-academy.usefedora.com/p/docker-devops&#34;&gt;Docker Essentials&lt;/a&gt;
alojado en &lt;a href=&#34;http://capside-academy.usefedora.com/&#34;&gt;Capside Academy&lt;/a&gt;. Además, lo impartía el
señor Javi Moreno, un verdadero crack del que tuve el honor de dar mis primeros pasos con Javascript
a partir de un curso que también impartió en el &lt;a href=&#34;https://cntg.xunta.es/web/cnt/home&#34;&gt;CNTG&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Si a Javi le apasionaba Docker, entonces la cosa tenía que ser interesante.&lt;/p&gt;

&lt;p&gt;Así que desempolvé los apuntes que nos había facilitado David y cuando pude sacar algo de tiempo (en realidad, pasaron muchos meses desde que descubrí el curso),
me lo devoré de cabo a rabo. Además, en paralelo, en el podcast de &lt;a href=&#34;http://wedevelopers.com/&#34;&gt;WeDevelopers&lt;/a&gt;
emitieron un capítulo de, exacto&amp;hellip; &lt;a href=&#34;http://wedevelopers.com/2016/11/12/we-developers-046-docker/&#34;&gt;Javi Moreno hablando de Docker!&lt;/a&gt;.
El universo me estaba enviando una señal, no cabía duda.&lt;/p&gt;

&lt;p&gt;Puedo afirmar con una mano en el corazón que desde el primer momento en el que empecé a cacharrear con Docker ya tenía claro que lo
iba a implantar en el trabajo. Ahora mismo lo estamos utilizando para nuestros entornos de desarrollo
y pronto lo tendremos listo para los entornos de preproducción.&lt;/p&gt;

&lt;p&gt;Aunque mi experiencia con Docker no es exhaustiva, ni larga, creo que los conceptos básicos
me han quedado bastante claros, así que voy a intentar plasmarlos aquí con el objetivo de ahorrarle
un par de horas a cualquiera que quiera comenzar con ello.&lt;/p&gt;

&lt;p&gt;Por otro lado, si eres un experto y ves que estoy metiendo la pata hasta el fondo&amp;hellip; vapuléame
en los comentarios! Sin piedad, en serio.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Empezamos!&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;para-qué-se-usa-docker&#34;&gt;¿Para qué se usa Docker?&lt;/h1&gt;

&lt;p&gt;En el 2010, la persona que había gestionado durante trece años el mantenimiento y evolución de
un importante sistema de información de la Xunta de Galicia decidió que era un buen momento
para cambiar de aires. Así que pidió la cuenta y se fué. Y como yo pasaba por allí, &lt;del&gt;me cayó el marrón&lt;/del&gt; me pasaron la responsabilidad.&lt;/p&gt;

&lt;p&gt;Repito: un sistema desarrollado durante trece años. Cuando se picó su primera línea de código,
no existía Google. Cuando yo lo cogí, el iPhone llevaba tres añitos entre nosotros. Os podéis hacer
una idea.&lt;/p&gt;

&lt;p&gt;El caso es que el entorno de desarrollo de dicho sistema era, cuanto menos&amp;hellip; caótico. Mil
dependencias en forma de librerías, algunas open source, otras código propietario, algunas obsoletas,
otras directamente demasiado exóticas o desconocidas&amp;hellip;&lt;/p&gt;

&lt;p&gt;Ignorando temas de mantenibilidad, (que es decir mucho, ya lo sé, pero sólo tenía un añito
de experiencia laboral!), el primer problema con el que me encontré es que dicho entorno de desarrollo
estaba perfectamente instalado y configurado&amp;hellip; en un único equipo. Como en los años 50, cuando
queríamos/necesitábamos realizar una mejora, implementar un cambio, corregir un bug&amp;hellip; un compañero
se movía físicamente a dicho equipo durante los días que hiciese falta (es decir, dejaba su
puesto de trabajo habitual durante días para irse a picar código a otro equipo que no era el suyo, a unas oficinas
que no eran de su empresa y con unos compañeros que no eran los suyos) para implementar la nueva
versión del sistema. Lo compilaba allí mismo, y enviaba los ejecutables por FTP al cabecilla de
turno para que los desplegase.&lt;/p&gt;

&lt;p&gt;Y procurábamos no pensar, por nuestra salud mental, qué pasaría si por alguna razón dicho
equipo ardía o era zapateado escaleras abajo. Todavía se me ponen los pelos de punta.&lt;/p&gt;

&lt;p&gt;Una locura.&lt;/p&gt;

&lt;p&gt;Como comentaba, era un sistema bastante importante (aunque no lo parezca) así que las presiones
por tener implementadas mejoras y correcciones eran prácticamente constantes todo el año. Estaba
descartada la idea de hacer un trabajo &amp;ldquo;forense&amp;rdquo; e intentar replicar el estado de dicho equipo de
desarrollo en otra máquina. Así que opté por utilizar una herramienta de VMWare
(el &lt;a href=&#34;http://www.vmware.com/products/converter.html&#34;&gt;vCenter Converter&lt;/a&gt;) que, básicamente,
escaneaba un sistema de ficheros entero alojado en una máquina física y lo convertía en una máquina
virtual. De esta manera, virtualicé (a cañonazos) el equipo de desarrollo, me lo metí en una memoria
externa y, oye, por lo menos podíamos dormir tranquilos: ya teníamos una copia virtual del entorno
de desarrollo, que podíamos ejecutar donde quisiéramos (siempre y cuando el equipo anfitrión
fuera lo suficientemente potente) y los desarrolladores ya no tenían que estar trabajando entre dos
sitios distintos. Quiero pensar que su calidad de vida incrementó enteros en aquel momento.&lt;/p&gt;

&lt;p&gt;¿Por qué os cuento esta historia? Porque Docker te permite, entre otras cosas,
&lt;strong&gt;replicar exactamente&lt;/strong&gt; el entorno de ejecución de un proyecto, de una manera muchísimo más
eficiente y rápida que la que buenamente implementé yo con el vCenter Converter. Eso sí, con matices
que iremos viendo paulatinamente.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;En realidad, si no empiezas tu proyecto usando Docker, puede ser bastante complicado replicar su
 entorno de ejecución a posteriori. Es más, en la historia que os cuento, sería como mínimo una tarea complicada y tediosa.
 Pero estas cosas las comentaremos más adelante en posts futuros.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Imaginad que puedo desplegar un entorno de ejecución de cualquier sistema/aplicación en un tiempo
ridículo (del orden de milisegundos) y siendo lo más eficiente posible en el uso de recursos. Pues eso es Docker.&lt;/p&gt;

&lt;p&gt;Partiendo de esto, podéis intuir que el paso de desarrollo a producción es indoloro (adiós a
aquello de &lt;em&gt;¡en mi máquina funcionaba!&lt;/em&gt;). En todos los escenarios (desarrollo, testing, preproducción, producción&amp;hellip;) tenemos exactamente
el mismo entorno (el mismo sistema operativo, la misma base de datos, las mismas librerías&amp;hellip; todo
en las versiones exactas). El margen para los problemas se estrecha bastante.&lt;/p&gt;

&lt;h1 id=&#34;todo-eso-está-muy-bien-pero-cómo-funciona&#34;&gt;Todo eso está muy bien, pero ¿cómo funciona?&lt;/h1&gt;

&lt;p&gt;En realidad, la tecnología que está en las tripas de Docker no es el último grito precisamente.
Emplea herramientas que llevan con nosotros muchos, muchos años. Si eres un experto en entornos
Unix, seguramente te suenen. Yo no lo soy, así que me sonaban vagamente cuando empecé con Docker.&lt;/p&gt;

&lt;p&gt;En Unix tenemos desde hace muchos años las siguientes funcionalidades:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://es.wikipedia.org/wiki/Chroot&#34;&gt;chroot&lt;/a&gt;: básicamente le indica a un proceso que su
sistema de ficheros empieza donde tú le digas. Es decir, cambias la raíz del sistema de ficheros
del proceso (de ahí su nombre, &lt;em&gt;change root&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cgroups&#34;&gt;cgroups&lt;/a&gt;: se utiliza para limitar en recursos la
ejecución de un proceso: memoria, ancho de banda, núcleos etc categorizando los procesos en diferentes &lt;em&gt;control groups&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://man7.org/linux/man-pages/man7/namespaces.7.html&#34;&gt;namespaces&lt;/a&gt;: útiles para aislar un proceso
del resto de procesos. Es decir, poder hacerle creer a un proceso que es el único que se está
ejecutando en toda la máquina.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pues perfecto, si ejecutamos un proceso aislado, limitado en recursos y le decimos que la raíz
de su sistema de ficheros está en un directorio donde tenemos almacenados casualmente los binarios de nuestro
entorno de ejecución (sistema operativo, base de datos, servidor de aplicaciones etc), &lt;em&gt;alehop!&lt;/em&gt;,
&lt;strong&gt;acabamos de virtualizar dicho entorno a nivel de sistema operativo&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Y esto es la idea principal de Docker: virtualización ligera a nivel de sistema operativo.
Usando procesos pequeños y rápidos en vez de pesadas máquinas virtuales. Y siendo muy eficientes
en los binarios que componen nuestro entorno de ejecución, como veremos en futuros posts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Estas son las tripas de Docker. La verdad detrás del truco, que necesitamos saber para no
caer en lo que comentaba el bueno de Arthur C. Clarke: &lt;em&gt;cualquier tecnología lo suficientemente
avanzada es indistinguible de la magia&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Pero para nuestro día a día, lo único que tenemos que tener claro es que Docker maneja la siguiente
arquitectura:&lt;/p&gt;


&lt;figure class=&#34;text-center w100&#34;&gt;
    
        &lt;img src=&#34;https://moisesvilar.github.io/images/docker-architecture.png&#34; alt=&#34;arquitectura de docker&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Modelo de componentes (muy simplificado) de Docker&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Es decir, tenemos un &lt;strong&gt;intérprete de Docker&lt;/strong&gt;, el &lt;em&gt;docker client&lt;/em&gt;, que se comunica con el sistema Docker
(el &lt;em&gt;docker server&lt;/em&gt;) a través de una API REST bajo HTTPS cuyo punto de acceso está implementado
en el proceso &lt;em&gt;docker agent&lt;/em&gt; que se ejecuta en background.&lt;/p&gt;

&lt;p&gt;Con cada comando que ejecutamos en Docker, por ejemplo:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -ti alpine /bin/sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;en realidad estamos invocando una o varias peticiones HTTPS a dicha API REST. ¡Incluso podríamos
comunicarnos con ella directamente empleando cURL por ejemplo!&lt;/p&gt;

&lt;p&gt;Es el &lt;em&gt;docker agent&lt;/em&gt; el encargado de procesar dicha llamada y comunicarse con el núcleo de Docker para que gestione la virtualización
de nuestros entornos utilizando las tres herramientas Unix que veíamos más arriba.&lt;/p&gt;

&lt;p&gt;Por último, decir que la máquina anfitrión, desde el punto de vista de Docker, es aquella que ejecuta
directamente el &lt;em&gt;docker server&lt;/em&gt;. Y para ello, el sistema operativo anfitrión debe &lt;strong&gt;soportar Docker de forma
nativa&lt;/strong&gt;. ¿Esto qué significa? Pues sencillamente, que tiene que implementar algo parecido a los &lt;em&gt;chroots&lt;/em&gt;,
&lt;em&gt;cgroups&lt;/em&gt; y &lt;em&gt;namespaces&lt;/em&gt; que veíamos más arriba. Es decir, tiene que darle las herramientas necesarias a Docker
para que éste haga su magia.&lt;/p&gt;

&lt;p&gt;Por el momento, basta con decir que cualquier sistema basado en Unix (Linux, MacOS) tiene soporte nativo de Docker. Y Windows 10 lo tiene en su versión
Professional, aunque he de decir que mi experiencia por el momento me dice que está bastante verde. Para el resto de
sistemas operativos (Windows 10 Home, Windows 8.1, Windows 7&amp;hellip;) habrá que utilizar un pequeño atajo para poder trabajar con Docker. ¡Pero no adelantemos acontecimientos!
Simplemente sabed que se puede.&lt;/p&gt;

&lt;h1 id=&#34;conclusiones&#34;&gt;Conclusiones&lt;/h1&gt;

&lt;p&gt;Lo sé. No ha sido un post muy exhaustivo, no tenemos código, ni comandos, ni sabemos cómo trabajar con Docker. Pero me
parece interesante asentar bien los conceptos básicos para lo que viene después. Lo que hemos visto aquí:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Docker te permite replicar entornos de ejecución en base a virtualización ligera a nivel de sistema operativo. Eso nos permite terminar de raíz con el problema de &lt;em&gt;¡en mi máquina funciona!&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Para realizar esa virtualización ligera, se apoya en tres herramientas que tenemos en Unix desde casi siempre: chroot, cgroups y namespaces, creando procesos aislados, limitados en recursos y que manejan un sistema de archivos que nosotros les decimos.&lt;/li&gt;
&lt;li&gt;Docker está implementado como una API REST sobre HTTPS. Cuando ejecutamos un comando, lo que realmente hacemos es invocar un método de esa API REST y Docker, tras el telón, hace su magia.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Por último, os invito de nuevo a escuchar el podcast de &lt;a href=&#34;http://wedevelopers.com/2016/11/12/we-developers-046-docker/&#34;&gt;Javi Moreno hablando de Docker!&lt;/a&gt; en WeDevelopers.
Y a realizar su curso de &lt;a href=&#34;http://capside-academy.usefedora.com/p/docker-devops&#34;&gt;Docker Essentials&lt;/a&gt; en Capside-Academy. Son sólo 20€ y os aseguro que estarán
bien invertidos. Así a todo, de vez en cuando escupen algún código promocional a través de &lt;a href=&#34;https://twitter.com/capside&#34;&gt;su cuenta de Twitter&lt;/a&gt;.
También es altamente recomendable seguir a &lt;a href=&#34;https://twitter.com/ciberado&#34;&gt;Javi en Twitter&lt;/a&gt; o poner su blog &lt;a href=&#34;https://programar.cloud/&#34;&gt;Programar en Cloud&lt;/a&gt; en tu lector de RSS favorito. Habla de Docker,
microservicios, testing&amp;hellip; y un montón de cosas interesantes.&lt;/p&gt;

&lt;p&gt;¡Nos vemos en el siguiente post!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>